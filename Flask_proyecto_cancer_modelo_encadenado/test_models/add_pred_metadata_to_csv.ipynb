{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import joblib  \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Suprimir warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El archivo con las predicciones crudas ha sido guardado en /Users/luiseduardogarciablanco/Desktop/bootcamp/Flask_proyecto_cancer_jpg_data/static/data/nuevo_dataset_con_predicciones.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1. Cargar el modelo entrenado\n",
    "model_path = '/Users/luiseduardogarciablanco/Desktop/bootcamp/Flask_proyecto_cancer_jpg_data/static/model/metadata_model.pkl'  # Reemplaza con la ruta de tu modelo\n",
    "modelo = joblib.load(model_path)  # Cargar el modelo entrenado\n",
    "\n",
    "# 2. Cargar el dataset de entrada (con los metadatos que usarás para predecir)\n",
    "dataset_path = '/Users/luiseduardogarciablanco/Desktop/bootcamp/Flask_proyecto_cancer_jpg_data/static/data/dataset_flask.csv'  # Reemplaza con la ruta del dataset\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "# Asegúrate de que 'X' sea el conjunto de características sobre las cuales el modelo predice\n",
    "X = df.drop(columns=['isic_id', 'target'])  # Eliminar columnas no relevantes para la predicción\n",
    "\n",
    "# 3. Hacer predicciones crudas (probabilidades)\n",
    "predicciones_crudas = modelo.predict_proba(X)  # Obtenemos las probabilidades\n",
    "\n",
    "# Si es un problema binario, puedes querer la probabilidad solo de la clase positiva\n",
    "# (asumiendo que la clase positiva es la segunda columna de la matriz de probabilidades)\n",
    "probabilidades_clase_positiva = predicciones_crudas[:, 1]\n",
    "\n",
    "# 4. Crear un nuevo dataframe con 'isic_id', 'target' y las predicciones crudas\n",
    "df_resultados = df[['isic_id', 'target']].copy()  # Copiar columnas 'isic_id' y 'target'\n",
    "df_resultados['prediccion_cruda'] = probabilidades_clase_positiva  # Añadir columna con las probabilidades crudas\n",
    "\n",
    "# 5. Guardar el nuevo dataset con las predicciones crudas\n",
    "output_path = '/Users/luiseduardogarciablanco/Desktop/bootcamp/Flask_proyecto_cancer_jpg_data/static/data/nuevo_dataset_con_predicciones.csv'  # Define dónde guardar el nuevo archivo\n",
    "df_resultados.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"El archivo con las predicciones crudas ha sido guardado en {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Haremos una nueva prueba de entrenamiento del modelo de imagenes resnet50 añadiendo la nueva columna como caracteristica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta donde se encuentran las imágenes y el archivo con predicciones crudas\n",
    "image_path = '/Users/luiseduardogarciablanco/Desktop/nueva data cancer/test web/jpg_ensambled_model'\n",
    "\n",
    "# Cargar los metadatos\n",
    "metadata_path = '/Users/luiseduardogarciablanco/Desktop/bootcamp/Flask_proyecto_cancer_jpg_data/static/data/nuevo_dataset_con_predicciones.csv'\n",
    "metadata = pd.read_csv(metadata_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Listar los dispositivos físicos disponibles, en este caso, GPUs\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "# Si hay alguna GPU disponible\n",
    "if len(physical_devices) > 0:\n",
    "    # Permitir que TensorFlow crezca dinámicamente la memoria utilizada en la GPU\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "physical_devices\n",
    "\n",
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(711, 3)\n",
      "(178, 3)\n"
     ]
    }
   ],
   "source": [
    "# Convertir la columna 'target' a string\n",
    "metadata['target'] = metadata['target'].astype(str)\n",
    "\n",
    "# Dividir los datos en entrenamiento y validación\n",
    "train_df, val_df = train_test_split(metadata, test_size=0.2, stratify=metadata['target'], random_state=42)\n",
    "\n",
    "print(train_df.shape)\n",
    "print(val_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Generador personalizado para combinar imágenes y predicción cruda\n",
    "class CustomDataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, dataframe, image_dir, batch_size, target_size, shuffle=True, mode='train'):\n",
    "        self.dataframe = dataframe\n",
    "        self.image_dir = image_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.target_size = target_size\n",
    "        self.shuffle = shuffle\n",
    "        self.mode = mode  # Puede ser 'train' o 'val'\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.dataframe) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch_data = self.dataframe.iloc[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        images = np.array([self._load_image(file_name) for file_name in batch_data['isic_id']])\n",
    "        predicciones_crudas = np.array(batch_data['prediccion_cruda']).reshape(-1, 1)\n",
    "        labels = np.array(batch_data['target']).astype('float32').reshape(-1, 1)\n",
    "\n",
    "        if self.mode == 'train':\n",
    "            return [images, predicciones_crudas], labels\n",
    "        else:\n",
    "            return [images, predicciones_crudas]\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            self.dataframe = self.dataframe.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    def _load_image(self, image_name):\n",
    "        img_path = os.path.join(self.image_dir, image_name + '.jpg')\n",
    "        img = load_img(img_path, target_size=self.target_size)\n",
    "        img_array = img_to_array(img)\n",
    "        img_array = preprocess_input(img_array)  # Aplicar normalización específica de ResNet50\n",
    "        return img_array\n",
    "\n",
    "# Crear los generadores de entrenamiento y validación\n",
    "train_gen = CustomDataGenerator(train_df, image_dir=image_path, batch_size=32, target_size=(256, 256), shuffle=True)\n",
    "val_gen = CustomDataGenerator(val_df, image_dir=image_path, batch_size=32, target_size=(256, 256), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_input (InputLayer)    [(None, 256, 256, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " resnet50 (Functional)       (None, 8, 8, 2048)           2358771   ['image_input[0][0]']         \n",
      "                                                          2                                       \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)         (None, 131072)               0         ['resnet50[0][0]']            \n",
      "                                                                                                  \n",
      " dense_4 (Dense)             (None, 128)                  1677734   ['flatten_2[0][0]']           \n",
      "                                                          4                                       \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)         (None, 128)                  0         ['dense_4[0][0]']             \n",
      "                                                                                                  \n",
      " prediccion_cruda_input (In  [(None, 1)]                  0         []                            \n",
      " putLayer)                                                                                        \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate  (None, 129)                  0         ['dropout_2[0][0]',           \n",
      " )                                                                   'prediccion_cruda_input[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dense_5 (Dense)             (None, 1)                    130       ['concatenate_2[0][0]']       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 40365186 (153.98 MB)\n",
      "Trainable params: 16777474 (64.00 MB)\n",
      "Non-trainable params: 23587712 (89.98 MB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Cargar el modelo preentrenado ResNet50 (sin la parte superior)\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(256, 256, 3))\n",
    "\n",
    "# Congelar las capas del modelo base\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Entrada de la imagen\n",
    "image_input = layers.Input(shape=(256, 256, 3), name='image_input')\n",
    "x = base_model(image_input)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(128, activation='relu')(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "# Entrada de la predicción cruda\n",
    "prediccion_cruda_input = layers.Input(shape=(1,), name='prediccion_cruda_input')\n",
    "\n",
    "# Concatenar ambas entradas\n",
    "combined = layers.Concatenate()([x, prediccion_cruda_input])\n",
    "\n",
    "# Capa de salida\n",
    "output = layers.Dense(1, activation='sigmoid', kernel_regularizer=l1_l2(l1=1e-5, l2=1e-4))(combined)\n",
    "\n",
    "# Definir el modelo\n",
    "model = models.Model(inputs=[image_input, prediccion_cruda_input], outputs=output)\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer=Adam(learning_rate=0.00001), loss='binary_crossentropy', metrics=['accuracy', Precision(), Recall(), tf.keras.metrics.AUC(name='auc')])\n",
    "\n",
    "# Resumen del modelo\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-06 19:19:25.108762: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - ETA: 0s - loss: 0.9405 - accuracy: 0.6222 - precision_3: 0.5714 - recall_3: 0.5677 - auc: 0.6572"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-06 19:19:30.795350: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 9s 296ms/step - loss: 0.9405 - accuracy: 0.6222 - precision_3: 0.5714 - recall_3: 0.5677 - auc: 0.6572 - val_loss: 0.5140 - val_accuracy: 0.7500 - val_precision_3: 0.6742 - val_recall_3: 0.8451 - val_auc: 0.8588\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 5s 239ms/step - loss: 0.7209 - accuracy: 0.7088 - precision_3: 0.6770 - recall_3: 0.6396 - auc: 0.7692 - val_loss: 0.4828 - val_accuracy: 0.8000 - val_precision_3: 0.7241 - val_recall_3: 0.8873 - val_auc: 0.8891\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 5s 239ms/step - loss: 0.5075 - accuracy: 0.7628 - precision_3: 0.7296 - recall_3: 0.7273 - auc: 0.8520 - val_loss: 0.4250 - val_accuracy: 0.8188 - val_precision_3: 0.7625 - val_recall_3: 0.8592 - val_auc: 0.8977\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 5s 240ms/step - loss: 0.5361 - accuracy: 0.7727 - precision_3: 0.7500 - recall_3: 0.7258 - auc: 0.8459 - val_loss: 0.3907 - val_accuracy: 0.8000 - val_precision_3: 0.8000 - val_recall_3: 0.7324 - val_auc: 0.9068\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 5s 239ms/step - loss: 0.4890 - accuracy: 0.8040 - precision_3: 0.8021 - recall_3: 0.7346 - auc: 0.8660 - val_loss: 0.3820 - val_accuracy: 0.8125 - val_precision_3: 0.8060 - val_recall_3: 0.7606 - val_auc: 0.9097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-06 19:19:55.188597: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - ETA: 0s - loss: 0.7388 - accuracy: 0.7358 - precision_4: 0.7003 - recall_4: 0.6958 - auc: 0.8059"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-06 19:20:01.940491: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 10s 343ms/step - loss: 0.7388 - accuracy: 0.7358 - precision_4: 0.7003 - recall_4: 0.6958 - auc: 0.8059 - val_loss: 0.4068 - val_accuracy: 0.8375 - val_precision_4: 0.8358 - val_recall_4: 0.7887 - val_auc: 0.9085\n",
      "Epoch 2/10\n",
      "22/22 [==============================] - 6s 274ms/step - loss: 0.5074 - accuracy: 0.8082 - precision_4: 0.7599 - recall_4: 0.8170 - auc: 0.8799 - val_loss: 0.4083 - val_accuracy: 0.8250 - val_precision_4: 0.7867 - val_recall_4: 0.8310 - val_auc: 0.9069\n",
      "Epoch 3/10\n",
      "22/22 [==============================] - 6s 271ms/step - loss: 0.3532 - accuracy: 0.8622 - precision_4: 0.8397 - recall_4: 0.8479 - auc: 0.9265 - val_loss: 0.4253 - val_accuracy: 0.8500 - val_precision_4: 0.8133 - val_recall_4: 0.8592 - val_auc: 0.9088\n",
      "Epoch 4/10\n",
      "22/22 [==============================] - 6s 278ms/step - loss: 0.3339 - accuracy: 0.8665 - precision_4: 0.8267 - recall_4: 0.8803 - auc: 0.9370 - val_loss: 0.4916 - val_accuracy: 0.8250 - val_precision_4: 0.7792 - val_recall_4: 0.8451 - val_auc: 0.8977\n"
     ]
    }
   ],
   "source": [
    "# Entrenamiento inicial (solo las capas superiores)\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    epochs=5,\n",
    "    validation_data=val_gen\n",
    ")\n",
    "\n",
    "# Descongelar algunas capas del modelo base para fine-tuning\n",
    "for layer in base_model.layers[-20:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Compilar de nuevo con una tasa de aprendizaje más baja\n",
    "model.compile(optimizer=Adam(learning_rate=1e-5), loss='binary_crossentropy', metrics=['accuracy', Precision(), Recall(), tf.keras.metrics.AUC(name='auc')])\n",
    "\n",
    "# Calcular los pesos de clase\n",
    "class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(train_df['target']), y=train_df['target'])\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "# Entrenamiento con Fine-Tuning\n",
    "history_fine = model.fit(\n",
    "    train_gen,\n",
    "    epochs=10,\n",
    "    validation_data=val_gen,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 189ms/step - loss: 0.4068 - accuracy: 0.8375 - precision_4: 0.8358 - recall_4: 0.7887 - auc: 0.9085\n",
      "Loss: 0.4068334102630615, Accuracy: 0.8374999761581421, Precision: 0.8358209133148193, Recall: 0.7887324094772339, AUC: 0.9084506630897522\n",
      "5/5 [==============================] - 1s 176ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.84      0.88      0.86        89\n",
      "     Class 1       0.84      0.79      0.81        71\n",
      "\n",
      "    accuracy                           0.84       160\n",
      "   macro avg       0.84      0.83      0.83       160\n",
      "weighted avg       0.84      0.84      0.84       160\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Función para recoger todas las etiquetas verdaderas del generador\n",
    "def get_all_labels(generator):\n",
    "    labels = []\n",
    "    for i in range(len(generator)):\n",
    "        _, batch_labels = generator[i]\n",
    "        labels.extend(batch_labels)\n",
    "    return np.array(labels).flatten()\n",
    "\n",
    "# Evaluar el modelo\n",
    "loss, accuracy, precision, recall, auc = model.evaluate(val_gen)\n",
    "print(f\"Loss: {loss}, Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}, AUC: {auc}\")\n",
    "\n",
    "# Predecir las probabilidades\n",
    "y_pred_probs = model.predict(val_gen)\n",
    "\n",
    "# Ajustar el umbral de decisión\n",
    "threshold = 0.5\n",
    "y_pred_adjusted = (y_pred_probs > threshold).astype(int).flatten()\n",
    "\n",
    "# Obtener las etiquetas verdaderas desde el generador\n",
    "y_true = get_all_labels(val_gen)\n",
    "\n",
    "# Asegurarse de que el número de predicciones coincida con el número de etiquetas verdaderas\n",
    "assert len(y_pred_adjusted) == len(y_true), \"El número de predicciones no coincide con el número de etiquetas reales.\"\n",
    "\n",
    "# Calcular y mostrar el reporte de clasificación\n",
    "print(classification_report(y_true, y_pred_adjusted, target_names=['Class 0', 'Class 1']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "salida del entrenamiento del modelo de imagenes con el añadido de la columna de resultado del modleo entrenado solo con mtadatos\n",
    "\n",
    "5/5 [==============================] - 1s 189ms/step - loss: 0.4068 - accuracy: 0.8375 - precision_4: 0.8358 - recall_4: 0.7887 - auc: 0.9085\n",
    "Loss: 0.4068334102630615, Accuracy: 0.8374999761581421, Precision: 0.8358209133148193, Recall: 0.7887324094772339, AUC: 0.9084506630897522\n",
    "5/5 [==============================] - 1s 176ms/step\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "     Class 0       0.84      0.88      0.86        89\n",
    "     Class 1       0.84      0.79      0.81        71\n",
    "\n",
    "    accuracy                           0.84       160\n",
    "   macro avg       0.84      0.83      0.83       160\n",
    "weighted avg       0.84      0.84      0.84       160\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/luiseduardogarciablanco/Desktop/bootcamp/Flask_proyecto_cancer_jpg_data/static/model/prueba_modelo_encadenado.pkl/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/luiseduardogarciablanco/Desktop/bootcamp/Flask_proyecto_cancer_jpg_data/static/model/prueba_modelo_encadenado.pkl/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo guardado en /Users/luiseduardogarciablanco/Desktop/bootcamp/Flask_proyecto_cancer_jpg_data/static/model/prueba_modelo_encadenado.pkl\n"
     ]
    }
   ],
   "source": [
    "# Ruta donde guardar el modelo\n",
    "model_save_path = '/Users/luiseduardogarciablanco/Desktop/bootcamp/Flask_proyecto_cancer_jpg_data/static/model/prueba_modelo_encadenado.pkl'\n",
    "\n",
    "# Guardar el modelo\n",
    "model.save(model_save_path)\n",
    "print(f\"Modelo guardado en {model_save_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
